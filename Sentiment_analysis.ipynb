{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtU1JdM8LA1JhGGg7WXcfQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hiteshjck/nlp/blob/main/Sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------------------------------------------------**Import Libraries**------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "R7_1MpFgVHVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-ENX8ixVFbt",
        "outputId": "c3841234-798f-4032-8f07-2394ccb6f2bf"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------------------------------------------------**Data Preprocessing**------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "sEmP-n7zrsEZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBwlrufHrVe5",
        "outputId": "49cb0337-a132-4ec2-d9c4-50aae842a1ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "                                              Review  Sentiment\n",
            "0  Fast shipping but this product is very cheaply...          1\n",
            "1  This case takes so long to ship and it's not e...          1\n",
            "2  Good for not droids. Not good for iPhones. You...          1\n",
            "3  The cable was not compatible between my macboo...          1\n",
            "4  The case is nice but did not have a glow light...          1\n",
            "25000\n"
          ]
        }
      ],
      "source": [
        "# Data preprocessing\n",
        "\n",
        "# reading csv using pandas\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "df = pd.read_csv('drive/MyDrive/nlp_data/AmazonReview.csv')\n",
        "\n",
        "print(df.head())\n",
        "print(len(df.index))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text cleaning\n",
        "\n",
        "# Handling missing values\n",
        "# no missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# 1. removing leading and trailing spaces\n",
        "df[\"Review\"] = df[\"Review\"].str.strip()\n",
        "\n",
        "# tokenization\n",
        "#df[\"tokenized review\"] = df.apply(lambda row: nltk.word_tokenize(row[\"Review\"]), axis=1)\n",
        "\n",
        "# Lowercasing\n",
        "df[\"Review\"] = df[\"Review\"].str.lower()\n",
        "\n",
        "# Map scores to sentiments (e.g., positive, neutral, negative)\n",
        "df['Sentiment value'] = df['Sentiment'].apply(lambda score: 'positive' if score > 3 else ('negative' if score < 3 else 'neutral'))\n",
        "print(df['Sentiment value'].value_counts())\n",
        "\n",
        "# Removing stop words (drops accuracy @1,2,3)\n",
        "# for i in stopwords.words('english'):\n",
        "#    df['Review'] = df[\"Review\"].str.replace(\" \"+i+\" \", \" \")\n",
        "\n",
        "# 2. Removing special characters (drops accuracy @1,2,3)\n",
        "# df[\"Review\"] = df[\"Review\"].str.replace(\"[\\\"$&+,:;=?@#|'<>.-^*()%!]\", \"\")\n",
        "\n",
        "print(df.head())\n",
        "print(len(df.index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVBYPk0JjWXH",
        "outputId": "f3dae90f-6383-4b13-c7d5-200fa6470a8f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative    10000\n",
            "positive     9999\n",
            "neutral      5000\n",
            "Name: Sentiment value, dtype: int64\n",
            "                                              Review  Sentiment  \\\n",
            "0  fast shipping but this product is very cheaply...          1   \n",
            "1  this case takes so long to ship and it's not e...          1   \n",
            "2  good for not droids. not good for iphones. you...          1   \n",
            "3  the cable was not compatible between my macboo...          1   \n",
            "4  the case is nice but did not have a glow light...          1   \n",
            "\n",
            "  Sentiment value  \n",
            "0        negative  \n",
            "1        negative  \n",
            "2        negative  \n",
            "3        negative  \n",
            "4        negative  \n",
            "24999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------------------------------------------- **1. Naive Bayes** -------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "nUkT3NO5sTjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sentiment analysis implementation\n",
        "# 1. Naive bayes algorithm\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Use TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "\n",
        "# Create TF-IDF matrices for training and testing data\n",
        "X_train = vectorizer.fit_transform(train_data['Review'])\n",
        "X_test = vectorizer.transform(test_data['Review'])\n",
        "\n",
        "# Use a simple model (Naive Bayes) as a starting point\n",
        "model = make_pipeline(MultinomialNB())\n",
        "model.fit(X_train, train_data['Sentiment value'])\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(test_data['Sentiment value'], predictions))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(test_data['Sentiment value'], predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA0dCFISsZsZ",
        "outputId": "c23a7a19-3d2f-40a7-db60-cd067e171dd8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6786\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.68      0.83      0.75      2021\n",
            "     neutral       0.48      0.04      0.08       985\n",
            "    positive       0.68      0.84      0.75      1994\n",
            "\n",
            "    accuracy                           0.68      5000\n",
            "   macro avg       0.61      0.57      0.53      5000\n",
            "weighted avg       0.64      0.68      0.62      5000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------------------------------ **2. Logistic Regression** ----------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "YVYQ82wo3-wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = TfidfVectorizer(max_features=2500)\n",
        "X = cv.fit_transform(df['Review'] ).toarray()\n",
        "\n",
        "df.loc[df['Sentiment']<=3,'Sentiment number'] = 0\n",
        "df.loc[df['Sentiment']>3,'Sentiment number'] = 1\n",
        "\n",
        "x_train ,x_test,y_train,y_test=train_test_split(X, df['Sentiment number'],\n",
        "                                                test_size=0.25, random_state=42)\n",
        "\n",
        "model=LogisticRegression()\n",
        "\n",
        "#Model fitting\n",
        "model.fit(x_train,y_train)\n",
        "\n",
        "#testing the model\n",
        "pred=model.predict(x_test)\n",
        "\n",
        "#model accuracy\n",
        "print(accuracy_score(y_test,pred))\n",
        "\n",
        "#df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMrRzsj42vqe",
        "outputId": "37e84a09-67ee-4160-9fb9-25e75eea7bcb"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------------------------ **3. Support Vector Machines (slow)** ----------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "W8t_A65m8Sj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newdf = df.copy()\n",
        "drop_indices = np.random.choice(newdf.index, 10000, replace=False)\n",
        "newdf = newdf.drop(drop_indices)\n",
        "print(newdf['Sentiment value'].value_counts())\n",
        "print(len(newdf.index))\n",
        "#newdf.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1Ty-mIJWx15",
        "outputId": "c439efa8-8606-4a29-f482-3eb73339376b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative    6049\n",
            "positive    6004\n",
            "neutral     2946\n",
            "Name: Sentiment value, dtype: int64\n",
            "14999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load and preprocess the dataset\n",
        "text = newdf['Review'].values\n",
        "labels = newdf['Sentiment value'].values"
      ],
      "metadata": {
        "id": "9Bgp2nQWVrgx"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Split the dataset into training and testing sets\n",
        "text_train, text_test, labels_train, labels_test = train_test_split(text, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Convert text data into numerical feature vectors\n",
        "vectorizer = CountVectorizer()\n",
        "features_train = vectorizer.fit_transform(text_train)\n",
        "features_test = vectorizer.transform(text_test)\n",
        "\n",
        "# Step 4: Train the SVM model\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(features_train, labels_train)\n",
        "\n",
        "\"\"\"Step 6: Predict sentiment on new data\n",
        "new_text = [\"I love this movie!\", \"This product is terrible.\", \"The food was delicious.\"]\n",
        "new_features = vectorizer.transform(new_text)\n",
        "new_predictions = svm.predict(new_features)\n",
        "print(new_predictions)\"\"\"\n",
        "\n",
        "# Step 7: Generate the classification report to evaluate the model\n",
        "predictions = svm.predict(features_test)\n",
        "print(\"Accuracy:\", accuracy_score(labels_test, predictions))\n",
        "print(\"\\n\",classification_report(labels_test, predictions))"
      ],
      "metadata": {
        "id": "ofDBYVbo8Vmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3382f1-5e03-4212-89b5-90650a5397a1"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6626666666666666\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.71      0.74      0.72      1231\n",
            "     neutral       0.35      0.32      0.33       585\n",
            "    positive       0.75      0.75      0.75      1184\n",
            "\n",
            "    accuracy                           0.66      3000\n",
            "   macro avg       0.60      0.60      0.60      3000\n",
            "weighted avg       0.66      0.66      0.66      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------------------------------- **4. LSTM** ----------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "LgoGxwFBaSPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://github.com/PSSABISHEK/sentiment_analysis_LSTM/blob/master/yeet_boi.ipynb\n",
        "\n"
      ],
      "metadata": {
        "id": "OzEVcwLCYDHj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}